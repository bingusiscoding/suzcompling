{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb31f237",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba0f94",
   "metadata": {},
   "source": [
    "The classification that we are interested for this program is that of document classification, specifically movie titles. Titles are the first thing we take in whenever something new is airing. Beyond the trailers, actors and directors involved, we read a name, and from there we decide whether it is worth a watch or more inquiery, or if it's a waste of our time. As an avid movie lover, I spend a lot of time reading about and watching movies, and an intriguing title is often what hooks me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2b8f0",
   "metadata": {},
   "source": [
    "Specifically for this paper I will be coding supervised classification, which is a feature extractor that converts inputs into a feature set, like positive or negative (linguist89, 2025). My thesis is that the most common features from a list of movies will have common features. To test for this, I will run my titles through a gender prediction based on nltk's name corpus, and see what averages there are for runtimes and genres in the most highly rated feature films from this data.\n",
    "\n",
    "I will start by following the document classification on the corpus by nltk on names, and using this framework to run a similar experiment for my own data, that being the titles of 2024 feature films.\n",
    "\n",
    "Note: I use terminology that may differ, but means the same: code, program, feature predictor, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3e19e",
   "metadata": {},
   "source": [
    "# 1. Packages to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee97f9",
   "metadata": {},
   "source": [
    "The first thing we do is import the necessary tools needed for our program. The first program I will be installing is the most important and the base for everything I will be doing, nltk (Natural Language Toolkit) then I will be importing random # nltk, regular expressions, and random module to support the preexisting tools built into nltk.\n",
    "\n",
    "The first program is nltk, which is the National Language Tool Kit. We have used this platform to build on data from corpuses and for language processing in class, and I find it to be a good tool for the scope of my paper (Hansen, Olsen and Enevoldsen, 2023). Please see the bibliography in the written portion of this exam for all references made in here. \n",
    "\n",
    "The next program is pandas, which lets us manipulate and see dataframes. We have used it in both the first and second semester of the master's program, so I see it fit to use this again for my set of data.\n",
    "\n",
    "Note that if there are hashtags in front of the !pip command, please remove these before attempting to run the code. They are simply there so the programs do not download over and over.\n",
    "\n",
    "A large portion of my code makes reference to homework we were assigned and worked with in class, which can be accessed through Stephan's github account (linguist89) or through this link: https://github.com/linguist89/compling25-exercises-week11. Please reach out to him or Ross if there are any issues accessing this worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, random # nltk, regular expression, random module\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter  # I will import Counter again later, but this is just to avoid any errors when running all the code at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eabc7",
   "metadata": {},
   "source": [
    "Although NLTK has a corpus of movie-related items, they are limited to reviews, and these reviews do not have information that is viable to my thesis, that being titles of movies, so I will move forward with their corpus containing names. From here, I will build on the gendered features we explored in class, and run similar code for the 2024 feature film titles.\n",
    "The goal is to see where this model places consistences for the titles involved, and if this is comparable to that of standard names.\n",
    "\n",
    "An example of an inquiry could be: are titles that are deemed more likely to be feminine more positively reviewed?\n",
    "\n",
    "This entire thing is a bit arbitrary, admittedly, but a curious case nonetheless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e573a",
   "metadata": {},
   "source": [
    "# 2. Gendered name identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a42ae5",
   "metadata": {},
   "source": [
    "This section is based largely on the code we worked with in class for week 11. This code builds on NLTK's corpus of names, and in class we coded to see if there was any reliability in assuming features of names being gendered. According to the homework notes \"The returned dictionary, known as a feature set, maps from features' names to their values. Feature names are case-sensitive strings that typically provide a short human-readable description of the feature. Feature values are values with simple types, such as booleans, numbers, and strings.\" (linguist89, 2025)\n",
    "\n",
    "For example, the last letter of the name Shrek is 'k', which is a letter we must map onto a set of variables we determine to be either female or male. This whole thing is quite binary, and there is no in-between encoding for gender-neutral names, as this was not a part of the corpus nor something I am able to append to the corpus data.\n",
    "\n",
    "Firstly, we write code which will extract the last letter of any given name (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    # Extracting the last letter of the word\n",
    "    return {'last_letter': word[-1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f9566",
   "metadata": {},
   "source": [
    "I will also run my own name below, for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features('Suzan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbabc36",
   "metadata": {},
   "source": [
    "Now that we have a feature extractor, we can move on to importing the corpus of names from NLTK. We will be randomizing the contents to ensure a widespread variety of data to work from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05106da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names # we import names to access the names in the corpus\n",
    "import random\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)\n",
    "len (names) # 7944 names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60498a",
   "metadata": {},
   "source": [
    "Following what was done in class, we now use the feature extractor to process the data and divide it into two groups, one training set and one test set. The training set trains a new \"naive Bayes\" classifier (linguist89, 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500] # test set is first 500 records\n",
    "# train set is everything after the first 500 records, actually 7544 names. We train on far\n",
    "# more data than we test\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) # 0.752\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217591dd",
   "metadata": {},
   "source": [
    "Let's see what happens if we get the first ten results from the training set, just to test that everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[:10] # first 10 records in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4f109",
   "metadata": {},
   "source": [
    "And again for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f92ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[:10] # first 10 records in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd6a5f",
   "metadata": {},
   "source": [
    "They both alternate quite well between feminine and masculine features, which is a good sign for us, and shows no current overrepresentation of either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174ac4a",
   "metadata": {},
   "source": [
    "Let's test out some names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e655e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(gender_features('Anna')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(gender_features('John')) # classify many names at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d41ad",
   "metadata": {},
   "source": [
    "What about a name we are sure is not a traditional name? I'm thinking of dear Smeagol AKA Gollum from Lord of the Rings. It will correctly classify both of his names as male, despite neither being present in the list of names from nltk.\n",
    "\n",
    "Oddly, Smeagol sometimes is predicted to be female instead of male. Run the cell again and it should fix the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e668944",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(gender_features('Gollum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(gender_features('Smeagol'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5539c",
   "metadata": {},
   "source": [
    "We continue to accounting for accuracy in the model between the classifier and with the data contained in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f557315",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3b792",
   "metadata": {},
   "source": [
    "My test set came out with an accuracy of 0.758, a number that varies based on the generated test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f43268",
   "metadata": {},
   "source": [
    "Let's see which features are the most informative for reaching this accuracy distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a69f8",
   "metadata": {},
   "source": [
    "With the most basic framework set, I will be continuing my program by importing my data and starting the relevant programming for my thesis below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aeccc",
   "metadata": {},
   "source": [
    "## 2.1 Picking the right features\n",
    "Relevant features of interest to this program are good to set in stone, so our model produces information that we can then use to see patterns of interest, like position of letters, lenght of names, or other features that might be universal for movies with better scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea565d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features\n",
    "# We have 54 features and one special feature for 'the', which gives us a total of 55 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test it out:\n",
    "gender_features2('Shrek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aed881",
   "metadata": {},
   "source": [
    "I also want to make an alternative one that includes special characters, for the sake of the movies in the spreadsheet. Some of them contain special characters like : or !, and I think it's interesting to include them as they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features_special(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    features[\"has(the)\"] = ('the' in name.lower())\n",
    "    for letter in '1234567890abcdefghijklmnopqrstuvwxyz&#@!$%^&*+-=;:,.?':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439100e",
   "metadata": {},
   "source": [
    "We have 64 features now, including special characters. I have added the word 'the' as a feature as it appears in many of the movie names. It will count out as 107 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ffb61",
   "metadata": {},
   "source": [
    "Let's compare the two by using the name Shrek with and without an exclamation mark in the two different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e49293",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features2(\"Shrek\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d189f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features2(\"Shrek!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011aa4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features_special(\"Shrek\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92deda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features_special(\"Shrek!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035deb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features_special(\"Shrek!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca76f20",
   "metadata": {},
   "source": [
    "As seen above, if I run the exclamation marked version of Shrek in the normal gender_features2, no parameters change, nor do they in the special (extended extractor) change the number. Each feature simply gets counted individually for whether it has each respective item in the special alphabet in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bff3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's prove this with another example:\n",
    "gender_features2('Window123')\n",
    "len(gender_features2('Window123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3167786",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features_special('Window123')\n",
    "len((gender_features_special('Window123')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f13db3",
   "metadata": {},
   "source": [
    "# 3. Classification of the 2024 movie title pool\n",
    "\n",
    "Now that we have the feature extractor, we can move on to the relevant data for this paper. \n",
    "\n",
    "I put all of the titles from the 2024 releases from the .csv file called IMDB_LIST_266_massive into a list called movie_titles. Admittedly, I got this list from the list I imported from IMDb and ran a Copilot script to automate the process of listing each of them into items in my list. \n",
    "\n",
    "Note that the order below is seemingly random, and is not based on alphabetical order, popularity or release date. I only know that this is ranked by an arbitrary \"list order\", which I cannot find the parameters for. The same order is of course in the IMDb spreadsheet, and was imported in this order from IMDb itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e561da0",
   "metadata": {},
   "source": [
    "Let's double check that all 266 titles are in here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451df75",
   "metadata": {},
   "source": [
    "Now comes the most intensive part of this program, that of importing the dataframe from the Excel (csv file) containing all of my data. There is a lot of data...\n",
    "\n",
    "We start by importing pandas, a toolkit that allows us to work with data in a user-friendly way, and is great for tables with lots of data. As we have worked with this on this course and for a course on the previous semester, I am a bit more familiar with it than I am with nltk.\n",
    "\n",
    "I will be using the official documentation from Pandas to guide my coding process, especially to make sure I do not make massive mistakes with my massive dataset (pandas documentation — pandas 2.2.3 documentation, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e5278",
   "metadata": {},
   "source": [
    "Please import the repository from this Github if the Wiseflow application has not imported the following two items https://github.com/bingusiscoding/suzcompling.git :\n",
    "1. IMDB_List_266_massive.csv\n",
    "2. Suz_Compling_Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b552e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# List files in the current directory\n",
    "print(\"Files in directory:\", os.listdir())\n",
    "\n",
    "# Update the path below if your file is not in the current directory\n",
    "csv_path = \"https://raw.githubusercontent.com/bingusiscoding/suzcompling/main/IMDB_LIST_266_massive.csv\"\n",
    "\n",
    "rawdata = pd.read_csv(csv_path, sep=';', quoting=1, encoding='utf-8')\n",
    "rawdata = rawdata.replace('*', '') \n",
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10aae31",
   "metadata": {},
   "source": [
    "There is a whole row which just repeats the titles for the dataframe. Let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa983c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us remove the row where Position is 'Position' (the header row accidentally included in the data)\n",
    "rawdata = rawdata[rawdata['Position'] != 'Position']\n",
    "rawdata = rawdata.reset_index(drop=True)\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d71c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The very first thing we're going to do is list all of the movie titles into a list\n",
    "movie_titles = rawdata['Title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef111ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if that worked as it should\n",
    "movie_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f002f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure we have all 266 movies, which is the number of rows in the original dataset\n",
    "len(movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe697e74",
   "metadata": {},
   "source": [
    "Admittedly, this is overkill. BUT! it does provide us with scores and a point of reference for how good a movie is beyond the features extractor I built earlier. \n",
    "\n",
    "Also, I spent way too many hours inputting the data, so bear with me for wanting to display it for a short while."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565c396",
   "metadata": {},
   "source": [
    "Let's group the columns we will want to use in the initial experiment for now. I will come back to the rest of the data more in the discursive parts of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25714ac3",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "df_small_beta = rawdata.groupby(['Position', 'Title', 'Runtime (mins)', 'Genres', 'Flickmetrix_total']).size().reset_index(name='Count')\n",
    "df_small_beta = df_small_beta.rename(columns={\n",
    "    'Position': 'Position',\n",
    "    'Title': 'Title',\n",
    "    'Runtime (mins)': 'Runtime',\n",
    "    'Genres': 'Genres',\n",
    "    'Flickmetrix_total': 'Flickmetrix_total'\n",
    "})\n",
    "df_small_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ef784",
   "metadata": {},
   "source": [
    "Some of the titles were not on Flick Metrix, so let's sort those out. We know that the cells without an input are simply empty, which is why we use the .isnull function. We can then strip them from the dataframe and index the final outcome as a new cleaned dataframe.\n",
    "\n",
    "Admittedly, I have struggled with getting the September 5 title to be correct in both the Excel file and in my code, so I will exclude it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where 'Flickmetrix_total' is missing or empty, or Title is 'September 5' or 'sep-05'\n",
    "missing_scores = df_small_beta[\n",
    "\tdf_small_beta['Flickmetrix_total'].isnull() |\n",
    "\t(df_small_beta['Flickmetrix_total'].astype(str).str.strip() == '') |\n",
    "\t(df_small_beta['Title'].str.strip().str.lower().isin(['september 5', 'sep-05']))\n",
    "]\n",
    "\n",
    "# Print the titles of the removed rows\n",
    "print(\"Removed rows (no Flickmetrix_total or problematic title):\")\n",
    "print(missing_scores[['Title', 'Flickmetrix_total']])\n",
    "\n",
    "# Remove those rows from the dataframe\n",
    "df_cleaned = df_small_beta[\n",
    "\t~(df_small_beta['Flickmetrix_total'].isnull() |\n",
    "\t  (df_small_beta['Flickmetrix_total'].astype(str).str.strip() == '') |\n",
    "\t  (df_small_beta['Title'].str.strip().str.lower().isin(['september 5', 'sep-05']))\n",
    "\t)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# I will lastly remove the titles from the movie_list list\n",
    "removed_titles = set(missing_scores['Title'].str.strip())\n",
    "movie_titles = [title for title in movie_titles if title.strip() not in removed_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see if these titles have been removed. Movie 183, 'Martin', is one that should now no longer be in the movie_titles list\n",
    "print('Martin' in movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cleaned) # Let's see how many we have left, it should be 246"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c484c8",
   "metadata": {},
   "source": [
    "## 3.1 Sorting\n",
    "\n",
    "Now we can get to the fun part: sorting!\n",
    "\n",
    "This subpart is more of a formality so that we can get different sets of sorting into respective dataframes. This makes the process of comparing different values and sorting orders easier later on.\n",
    "\n",
    "The reason I focus on titles, runtime, and genres for this programming is that these are the most common things we watch out for when picking a movie to watch. Subcategorizations with actors and directors is a much more biased line of researching which is far too expansive for this paper - for example, someone who likes movies from one director is more likely to watch the rest of the movies from that director, even if they have bad ratings.\n",
    "\n",
    "We are all also different in our tastes and in our general moods. Some people love long movies, some will sigh if a movie is anything over 2 hours long. Some love horror movies, others find them repulsive and will want to steer clear of any. For this reason, I will keep these categories (mostly) separated for most of my coding going forward.\n",
    "\n",
    "Let's start by making sure we have all 246 movies that contain a Flick Metrix score and see them in alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_cleaned.value_counts(['Title', 'Flickmetrix_total']).sort_index(ascending=True)\n",
    "print(total)\n",
    "#And the length of the total just below, it should say 247\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7114fc",
   "metadata": {},
   "source": [
    "We start by making a dataframe that indexes by title in alphabetical order (ascending):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickmetrix_sorted = df_cleaned.sort_values(['Title', 'Flickmetrix_total'], ascending=True)\n",
    "flickmetrix_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we do the same with genres, it shows the entire groups of genres, while we are interested in the individual ones.\n",
    "genres_sorted = df_cleaned.sort_values((['Genres','Title']), ascending=True)\n",
    "genres_sorted.value_counts('Genres')\n",
    "genres_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6854d5e",
   "metadata": {},
   "source": [
    "As some of these movies have multiple genres, I needed to import defaultdict, which is a tool that helps me do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary to store genres and the titles they appear in\n",
    "genre_titles = defaultdict(set)\n",
    "\n",
    "# We run a for loop to iterate over the dataframe and split genres by comma\n",
    "for _, row in df_cleaned.iterrows():\n",
    "    genres = [g.strip() for g in row['Genres'].split(',')]\n",
    "    for genre in genres:\n",
    "        genre_titles[genre].add(row['Title'])\n",
    "\n",
    "# Print the count of titles per genre and example titles\n",
    "for genre, titles in genre_titles.items():\n",
    "    print(f\"{genre}: {len(titles)} titles, e.g. {list(titles)[:10]}\")\n",
    "\n",
    "# And a DataFrame to summarize the genres and their titles\n",
    "genre_titles_df = pd.DataFrame({\n",
    "    'Genre': list(genre_titles.keys()),\n",
    "    'Number of Titles': [len(titles) for titles in genre_titles.values()],\n",
    "    'Titles': [', '.join(sorted(titles)) for titles in genre_titles.values()]\n",
    "})\n",
    "\n",
    "genre_titles_df\n",
    "\n",
    "# We have two different outputs below, one with the genres sorted by number of titles and listing the ones included\n",
    "# and one which is a more easy-on-the-eye dataframe with genres, number of titles, and some of the titles.\n",
    "# Note: I'm not sure how to make the dataframe show all the titles, so it only shows the first few titles in each genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dc505",
   "metadata": {},
   "source": [
    "And lastly (for now), by runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important step here is to convert the runtime column to numeric, so we can sort it as such.\n",
    "df_cleaned['Runtime'] = pd.to_numeric(df_cleaned['Runtime'], errors='coerce')\n",
    "runtime_sorted = df_cleaned.sort_values('Runtime', ascending=False)\n",
    "runtime_sorted.head(10)  # Display the top 10 longest movies\n",
    "# If correctly done, The Brutalist should be a whopping 216 minutes long (3.6 hours),\n",
    "# and the shortest movie should be Look Back with 58 minutes (just two minutes shy of an hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test out how it looks for a single movie, which we can only by calling it as a boolean\n",
    "tester1 = df_cleaned[df_cleaned['Title'] == 'Look Back']\n",
    "tester1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d39db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now three of my favorite movies from the list, the isin (is in) function allows us to check for multiple values\n",
    "tester1 = df_cleaned[df_cleaned['Title'].isin(['Challengers', 'Conclave', 'Drive-Away Dolls'])]\n",
    "# We will sort this by Flickmetrix_total, descending\n",
    "tester1.sort_values('Flickmetrix_total', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us run tester1 by runtime in descending order\n",
    "tester1_sorted = tester1.sort_values('Runtime', ascending=False)\n",
    "tester1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa701d00",
   "metadata": {},
   "source": [
    "To progress to the final stages, we have needed these four items: the list of the movie titles, the runtime, the genres, and the Flick Metrix scores. Now that we have all four, we can proceed to the next part, where we combine it all with the gender features coding we did way earlier, and from this we will start to deduce if there are any patterns between these four parameters and the gender features. \n",
    "\n",
    "I do this to not just run the entire list of movies through the (quite arbitrary) name model, but to have a point of comparison - any patterns with the other factors add some credibility to the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6b4c4",
   "metadata": {},
   "source": [
    "# 4. Let's combine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f3d8d",
   "metadata": {},
   "source": [
    "For this section we can finally begin to combine our classifyer with the sorted dataframes from section 3.1\n",
    "\n",
    "I will be importing a collection from the Python datatypes called Counter, which helps in providing tallies - of which there will presumably be a lot of for each letter and number in our specialized alphabet (collections — Container datatypes, no date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1094f7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Extract the titles from df_cleaned\n",
    "titles_cleaned = df_cleaned['Title'].tolist()\n",
    "\n",
    "# Extract features for each title\n",
    "title_features_cleaned = [gender_features(title) for title in titles_cleaned]\n",
    "\n",
    "# Classify each title using the trained classifier\n",
    "title_genders_cleaned = [classifier.classify(features) for features in title_features_cleaned]\n",
    "\n",
    "# Count occurrences of each predicted gender\n",
    "gender_counts_cleaned = Counter(title_genders_cleaned)\n",
    "print(\"Predicted gender counts for df_cleaned titles:\", gender_counts_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63a2c7",
   "metadata": {},
   "source": [
    "Let's follow this up by creating a more comprehensive dataframe that includes the movie titles and their predicted genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3326291",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# A DataFrame with titles and their predicted gender\n",
    "# Use df_cleaned for titles and predicted gender\n",
    "gender_df = pd.DataFrame({\n",
    "    'Title': titles_cleaned,\n",
    "    'Predicted Gender': title_genders_cleaned\n",
    "})\n",
    "\n",
    "# Merge with Flickmetrix scores from df_cleaned\n",
    "gender_df = gender_df.merge(flickmetrix_sorted[['Title', 'Flickmetrix_total']], on='Title', how='left')\n",
    "\n",
    "# And runtime\n",
    "gender_df = gender_df.merge(runtime_sorted[['Title', 'Runtime']], on='Title', how='left')\n",
    "\n",
    "# And genres\n",
    "gender_df = gender_df.merge(genres_sorted[['Title', 'Genres']], on='Title', how='left')\n",
    "\n",
    "# Convert Flickmetrix_total to numeric for sorting\n",
    "gender_df['Flickmetrix_total'] = pd.to_numeric(gender_df['Flickmetrix_total'], errors='coerce')\n",
    "\n",
    "# Separate female and male titles, sort by Flickmetrix score descending\n",
    "female_titles = gender_df[gender_df['Predicted Gender'] == 'female'].sort_values('Flickmetrix_total', ascending=False).reset_index(drop=True)\n",
    "male_titles = gender_df[gender_df['Predicted Gender'] == 'male'].sort_values('Flickmetrix_total', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#Finally, we can display the top 20 titles sorted by Flickmetrix score. This is just to show a baseline of the data.\n",
    "gender_df.sort_values('Flickmetrix_total', ascending=False).head(20).style.format({'Flickmetrix_total': '{:.0f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1274e",
   "metadata": {},
   "source": [
    "From a first glance it seems that movies with \"male\" titles have the highest score. Let's explore why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73e9fc",
   "metadata": {},
   "source": [
    "We start by wrangling the letters to see which ones are the most common overall. Then we move onto the most common last letter of words.\n",
    "\n",
    "Looking at all of the letters is mostly for fun, but does give us an idea of what it could look like for the last letters in the proceeding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first exclude all of the instances of 'the' \n",
    "movie_titles_no_the = [re.sub(r'\\bthe\\b', '', title, flags=re.IGNORECASE).strip() for title in movie_titles]\n",
    "\n",
    "# Display a few examples to verify\n",
    "print(movie_titles[:10])\n",
    "print(movie_titles_no_the[:10])# Join all movie titles into a single string and convert to lowercase. We convert to lowercase to ensure uniformity in counting letters.\n",
    "all_letters = ''.join(movie_titles).lower()\n",
    "\n",
    "# Count each letter\n",
    "letter_counts = Counter(all_letters)\n",
    "\n",
    "# Display the counts for each letter (a-z + special characters), sorted by count descending\n",
    "for letter, count in sorted(letter_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{letter}: {count}\")\n",
    "\n",
    "# It will display the original titles, then the titles without 'the', and finally the counts of each letter in the titles, sorted in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe9141",
   "metadata": {},
   "source": [
    "We can't test for accuracy because none of the titles have an actual gender assigned, meaning that there are no true labels for gendering which nltk can predict accuracy on. However, we do have informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us get the most informative last letters for movie titles in determining gender.\n",
    "\n",
    "# Extract last letters and predicted genders for each movie title\n",
    "last_letters = [features['last_letter'].lower() for features in title_features_cleaned]\n",
    "gender_labels = title_genders_cleaned\n",
    "\n",
    "# Count (last_letter, gender) pairs\n",
    "pair_counts = Counter(zip(last_letters, gender_labels))\n",
    "\n",
    "# For each last letter, compute the ratio of male to female predictions\n",
    "letter_stats = {}\n",
    "for letter in set(last_letters):\n",
    "    male_count = pair_counts.get((letter, 'male'), 0)\n",
    "    female_count = pair_counts.get((letter, 'female'), 0)\n",
    "    total = male_count + female_count\n",
    "    if total > 0:\n",
    "        ratio = male_count / total\n",
    "        letter_stats[letter] = {'male': male_count, 'female': female_count, 'ratio_male': ratio, 'total': total}\n",
    "\n",
    "# Sort by informativeness: letters with high skew toward one gender and enough samples\n",
    "informative_letters = sorted(\n",
    "    letter_stats.items(),\n",
    "    key=lambda x: abs(x[1]['ratio_male'] - 0.5) * x[1]['total'],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Display the top 10 most informative last letters\n",
    "print(\"Most informative last letters for movie title gender prediction:\")\n",
    "for letter, stats in informative_letters[:10]:\n",
    "    print(f\"Last letter '{letter}': male={stats['male']}, female={stats['female']}, total={stats['total']}, male_ratio={stats['ratio_male']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbce03",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# In a dataframe:\n",
    "informative_features_df = pd.DataFrame.from_dict(letter_stats, orient='index')\n",
    "informative_features_df.index.name = 'last_letter'\n",
    "informative_features_df = informative_features_df.reset_index()\n",
    "\n",
    "# Sort by informativeness: letters with high skew toward one gender and enough samples\n",
    "informative_features_df['informativeness'] = informative_features_df['total'] * abs(informative_features_df['ratio_male'] - 0.5) \n",
    "# We ratio it to male as we know it has a higher count than for female features\n",
    "informative_features_df = informative_features_df.sort_values('informativeness', ascending=False)\n",
    "\n",
    "# Print last letter and its statistics\n",
    "for _, row in informative_features_df.iterrows():\n",
    "    print(f\"Last letter '{row['last_letter']}': male={row['male']}, female={row['female']}, total={row['total']}, male_ratio={row['ratio_male']:.2f}\")\n",
    "\n",
    "informative_features_df.sort_values('total', ascending=False).head(20)\n",
    "\n",
    "#Note: the first column shows the letter based on the most informative features from the test set in the initial classifier model of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b13f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_letter_to_titles = defaultdict(list)\n",
    "for title, features in zip(movie_titles, title_features_cleaned):\n",
    "    last_letter = features['last_letter'].lower()\n",
    "    last_letter_to_titles[last_letter].append(title)\n",
    "\n",
    "# Print the last letter and the corresponding movie titles\n",
    "for letter, titles in last_letter_to_titles.items():\n",
    "    print(f\"Last letter '{letter}': {titles}\")\n",
    "\n",
    "# Convert the letter_stats dictionary to a DataFrame\n",
    "letter_stats_df = pd.DataFrame.from_dict(letter_stats, orient='index')\n",
    "letter_stats_df.index.name = 'last_letter'\n",
    "letter_stats_df = letter_stats_df.reset_index()\n",
    "letter_stats_df = letter_stats_df.sort_values(by='total', ascending=False)\n",
    "\n",
    "letter_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5ba31",
   "metadata": {},
   "source": [
    "Now let's see what common grounds we can settle on for the common last letters of these movies. I will take the first 10 features into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 10 most common last letters in the cleaned movie titles\n",
    "\n",
    "# Get last letters from cleaned titles\n",
    "last_letters_cleaned = [features['last_letter'].lower() for features in title_features_cleaned]\n",
    "last_letter_counts = Counter(last_letters_cleaned)\n",
    "top_10_letters = [letter for letter, _ in last_letter_counts.most_common(10)]\n",
    "\n",
    "# Prepare results\n",
    "results = []\n",
    "\n",
    "for letter in top_10_letters:\n",
    "    # Filter df_cleaned for titles ending with this last letter\n",
    "    mask = [features['last_letter'].lower() == letter for features in title_features_cleaned]\n",
    "    subset = df_cleaned[mask]\n",
    "    # Calculate average runtime\n",
    "    avg_runtime = int(round(subset['Runtime'].mean()))\n",
    "    # Get all genres, split and count\n",
    "    all_genres = subset['Genres'].str.split(',').explode().str.strip()\n",
    "    genre_counts = all_genres.value_counts().head(5)  # Top 5 genres for brevity\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    results.append({\n",
    "        'last_letter': letter,\n",
    "        'count': len(subset),\n",
    "        'avg_runtime': avg_runtime,\n",
    "        'top_genres': genre_counts.to_dict()\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Display as DataFrame\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's expand the top_genres to show every genre for each last letter\n",
    "for entry in results:\n",
    "\tprint(f\"Last letter: {entry['last_letter']}, Top genres: {entry['top_genres']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare to what we did in the sorting, where we generated the genre_titles_df and sorted it by the number of titles.\n",
    "# Drama, Thriller and Action were the three most common genres, making this average very likely.\n",
    "genre_titles_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21e996",
   "metadata": {},
   "source": [
    "Additionally, since we calculated the runtime while generating the average for the genres, we now have a complete overview of what we need. \n",
    "\n",
    "The very last thing to do in this code is to compare the average gender features connected to the average of the other parameters.\n",
    "\n",
    "Finally, we can see whether movie titles that are the highest rated are most commonly coded as male or as female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bdf0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the title(s) with the highest Flickmetrix score\n",
    "max_score = gender_df['Flickmetrix_total'].max()\n",
    "top_titles = gender_df[gender_df['Flickmetrix_total'] == max_score]\n",
    "\n",
    "# Get their last letters\n",
    "top_titles['last_letter'] = top_titles['Title'].str[-1].str.lower()\n",
    "\n",
    "# Get the most common last letter(s) among all titles\n",
    "most_common_last_letter = top_10_letters[0]  # 'e', from previous results\n",
    "\n",
    "print(\"Title(s) with the highest Flickmetrix score:\")\n",
    "print(top_titles[['Title', 'Flickmetrix_total', 'last_letter', 'Predicted Gender']])\n",
    "\n",
    "print(f\"\\nMost common last letter among all titles: '{most_common_last_letter}'\")\n",
    "print(\"Top 10 most common last letters and their stats:\")\n",
    "for entry in results:\n",
    "    print(f\"Last letter: {entry['last_letter']}, Count: {entry['count']}, Avg runtime: {entry['avg_runtime']}, Top genres: {entry['top_genres']}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e9709",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Add most common predicted gender for each last letter to the results table\n",
    "results_with_gender = []\n",
    "\n",
    "for entry in results:\n",
    "    letter = entry['last_letter']\n",
    "    # Find indices in title_features_cleaned where last_letter matches\n",
    "    mask = [features['last_letter'].lower() == letter for features in title_features_cleaned]\n",
    "    # Get predicted genders for these titles\n",
    "    genders = [g for g, m in zip(title_genders_cleaned, mask) if m]\n",
    "    # Count most common gender\n",
    "    if genders:\n",
    "        most_common_gender = Counter(genders).most_common(1)[0][0]\n",
    "    else:\n",
    "        most_common_gender = None\n",
    "    entry_with_gender = entry.copy()\n",
    "    entry_with_gender['most_common_gender'] = most_common_gender\n",
    "    results_with_gender.append(entry_with_gender)\n",
    "\n",
    "# Display as DataFrame\n",
    "pd.DataFrame(results_with_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate female to male ratio for the 10 most common last letters\n",
    "ratios = []\n",
    "for entry in results_with_gender[:10]:\n",
    "    # Only process if entry is a dict or a tuple whose second element is a dict with 'last_letter'\n",
    "    entry_dict = None\n",
    "    if isinstance(entry, dict) and 'last_letter' in entry:\n",
    "        entry_dict = entry\n",
    "    elif isinstance(entry, tuple) and len(entry) > 1 and isinstance(entry[1], dict) and 'last_letter' in entry[1]:\n",
    "        entry_dict = entry[1]\n",
    "    # Skip entries that do not have the expected structure\n",
    "    if entry_dict is None:\n",
    "        continue\n",
    "    letter = entry_dict['last_letter']\n",
    "    # Find indices in title_features_cleaned where last_letter matches\n",
    "    mask = [features['last_letter'].lower() == letter for features in title_features_cleaned]\n",
    "    # Get predicted genders for these titles\n",
    "    genders = [g for g, m in zip(title_genders_cleaned, mask) if m]\n",
    "    female_count = genders.count('female')\n",
    "    male_count = genders.count('male')\n",
    "    ratio = female_count / male_count if male_count > 0 else float('inf')\n",
    "    ratios.append({\n",
    "        'last_letter': letter,\n",
    "        'female': female_count,\n",
    "        'male': male_count,\n",
    "        'female_to_male_ratio': ratio,\n",
    "        'most_common_gender': entry_dict.get('most_common_gender')\n",
    "    })\n",
    "\n",
    "ratios_df = pd.DataFrame(ratios)\n",
    "\n",
    "# Top 20 movies by Flickmetrix score with gender attached\n",
    "top20 = gender_df.sort_values('Flickmetrix_total', ascending=False).head(20)[['Title', 'Predicted Gender', 'Flickmetrix_total']]\n",
    "print(\"\\nTop 20 scores from Flick Metrix with predicted gender attached:\")\n",
    "top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write some code to calculate the specific ratio between male and female counts\n",
    "male_count = (top20['Predicted Gender'] == 'male').sum()\n",
    "female_count = (top20['Predicted Gender'] == 'female').sum()\n",
    "if female_count > 0:\n",
    "    male_female_ratio = male_count / female_count\n",
    "else:\n",
    "    male_female_ratio = float('inf')\n",
    "print(f\"\\nIn the top 20: male={male_count}, female={female_count}, male/female ratio={male_female_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330da57d",
   "metadata": {},
   "source": [
    "That's it! We can now prove by the metrics that for the pool of 2024 releases favor an average runtime of 115-116 minutes, having the genres of drama, thriller and action, and are determined to have male features for their titles, usually ending in e, s, or n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
